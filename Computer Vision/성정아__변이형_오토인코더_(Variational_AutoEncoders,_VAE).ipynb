{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "성정아 - _변이형 오토인코더 (Variational AutoEncoders, VAE).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_60ssUVlU0"
      },
      "source": [
        "# 이미지 생성 모델\n",
        "\n",
        "- 이미지 잠재 공간에서 샘플링하여 완전히 새로운 이미지나 기존 이미지를 변형시키는 방식의 주요 기법\n",
        "  - 변이형 오토인코더(Variational AutoEncoders, VAE)\n",
        "  \n",
        "  - 적대적 생성 네트워크(Generative Adversarial Networks, GAN)\n",
        "\n",
        "- 잠재 공간의 한 포인트를 입력으로 받아 이미지(픽셀의 그리드)를 출력하는 모듈을 VAE에서는 디코더(decoder)라고 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G-2CNkNYvZI"
      },
      "source": [
        "## 잠재 공간(Latent Space)\n",
        "\n",
        "<img src=\"https://images.deepai.org/converted-papers/2007.08383/x1.png\">\n",
        "\n",
        "<sub>[이미지 출처] https://deepai.org/publication/deep-learning-in-protein-structural-modeling-and-design</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM5AhdH7AGgf"
      },
      "source": [
        "# 변이형 오토인코더(Variational AutoEncoders, VAE)\n",
        "\n",
        "- 입력 이미지를 잠재 공간의 고정된 코딩으로 압축하는 대신  \n",
        "  이미지를 어떤 통계 분포의 파라미터로 변환 \n",
        "  \n",
        "- 평균과 분산 파라미터를 사용하여 이 분포에서 무작위로 하나의 샘플을 추출\n",
        "\n",
        "- 해당 샘플을 디코딩하여 원본 입력으로 복원\n",
        "\n",
        "- 위 과정은 안정성을 향상, 잠재 공간 어디에서든 의미있는 표현을 인코딩하게 함\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/variationalautoencoder-170601084514/95/variational-autoencoder-21-638.jpg?cb=1496306885\">\n",
        "\n",
        "  <sub>[이미지 출력] https://www.slideshare.net/ssuser06e0c5/variational-autoencoder-76552518</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- VAE의 훈련\n",
        "\n",
        "  - 디코딩된 샘플이 원본 입력과 동일하도록 만드는 재구성 손실(reconstruction loss)\n",
        "\n",
        "  - 잠재 공간을 잘 형성하고 훈련 데이터에 과적합을 줄이는 규제 손실(regularization loss)\n",
        "\n",
        "- VAE 구현의 pseudocode\n",
        "\n",
        "      z_mean, z_log_var = encoder(input_img)\n",
        "      \n",
        "      z = z_mean + exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "      recontructed_img = decoder(z)\n",
        "\n",
        "      model = Model(input_img, reconstructed_img)\n",
        "\n",
        "      재구성 손실과 규제 손실을 사용하여 훈련\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6TPr96HOE2b"
      },
      "source": [
        "# Convolutional VAE\n",
        "\n",
        "- MNIST Dataset\n",
        "\n",
        "- 코드 참조 : https://www.tensorflow.org/tutorials/generative/cvae?hl=ko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## 모듈 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-JuIu2N_SQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cc8d46-5f46-4ee0-a0ae-aa2b31e9abd8"
      },
      "source": [
        "!pip install tensorflow-probability\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (0.1.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-ff3gjzw8\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-ff3gjzw8\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (0.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (3.12.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorflow-docs===0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-) (50.3.2)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54_-cp36-none-any.whl size=144911 sha256=a24f8458276bab57d1c72ab6927ff44c651ce4c7bc57bdd9a4df1bd3a97cfcaf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-egyu4ara/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.070f8a1484cf809ec5bbe7aafa4fb5970a8c2ac54-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "import numpy as np\n",
        "import PIL \n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, Conv2D, InputLayer\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4fYMGxGhrna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9d0d09-cdaf-471b-8d89-e7ccef9f8c5a"
      },
      "source": [
        "(train_images, _), (test_images, _) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhIG4lijPiAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5f3d1b-c345-476f-daac-8ada6cd32d0b"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSIJQvcbPZ9z"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFC2ghIdiZYE"
      },
      "source": [
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Me98uqPckY"
      },
      "source": [
        "train_images = preprocess_images(train_images)\n",
        "test_iamges =preprocess_images(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eND2fTiPhmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0a2c1c-9c0f-43ae-c739-08f5ee25297e"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "source": [
        "train_size = 20000\n",
        "batch_size = 32\n",
        "test_size = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIGN6ouoQxt3"
      },
      "source": [
        "## tf.data 를 사용하여 데이터 일괄 처리 및 섞기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yKCCQOoJ7cn"
      },
      "source": [
        "train_dataset = (Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## 인코더, 디코더 모델 구성\n",
        "\n",
        "- VAE 예제에서는 인코더 및 디코더 네트워크에 두 개의 작은 ConvNet을 사용\n",
        "\n",
        "- 자세한 네트워크 구성 설명은 링크 참조\n",
        " \n",
        "  - https://www.tensorflow.org/tutorials/generative/cvae?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGLbvBEmjK0a"
      },
      "source": [
        "class CAVE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CAVE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = Sequential([InputLayer(input_shape=(28, 28, 1)),\n",
        "                               Conv2D(filters=32, kernel_size=3,\n",
        "                                      strides=(2, 2), activation='relu'),\n",
        "                               Conv2D(filters=64, kernel_size=3,\n",
        "                                      strides=(2, 2), activation='relu'),\n",
        "                               Flatten(),\n",
        "                               Dense(latent_dim + latent_dim)])\n",
        "    \n",
        "    self.decoder = Sequential([InputLayer(input_shape=(latent_dim, )),\n",
        "                               Dense(units=7*7*32, activation='relu'),\n",
        "                               Reshape(target_shape=(7, 7, 32)),\n",
        "                               Conv2DTranspose(filters=64, kernel_size=3,\n",
        "                                              strides=2, padding='same',\n",
        "                                              activation='relu'),\n",
        "                               Conv2DTranspose(filters=32, kernel_size=3,\n",
        "                                               strides=2, padding='same',\n",
        "                                               activation='relu'),\n",
        "                               Conv2DTranspose(filters=1, kernel_size=3,\n",
        "                                               strides=1, padding='same'),])\n",
        "    \n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "\n",
        "    return logits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## 손실 함수 및 최적화 프로그램 정의\n",
        "\n",
        "- VAE는 한계 로그 우도에서 증거 하한 (ELBO)을 최대화하여 학습\n",
        "\n",
        "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
        "\n",
        "- 실제로 우리는이 기대치의 단일 샘플 Monte Carlo 추정치를 최적화\n",
        "\n",
        "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yu0T6zZQ2yn"
      },
      "source": [
        "optimizer = Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2 * np.pi)\n",
        "  return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logpz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x) \n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## 모델 학습 및 이미지 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvWlFXs2RCkN"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "latent_dim = 2\n",
        "num_examples_to_generate =16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmBtrthyP0qZ"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "source": [
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "\n",
        "model = CAVE(latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "source": [
        "def generate_and_save_imamges(model, epoch, test_sample):\n",
        "  mean, logvar = model.encode(test_sample)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  predictions = model.sample(z)\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sDBkpNmeOQ4"
      },
      "source": [
        "assert batch_size >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n",
        "\n",
        "##이부분부터 계속 에러가 뜨는데 찾지 못하여 미리 제출하고 나중에 영상 다시 보면서 찾아보겠습닙다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoI_fVeieQwN"
      },
      "source": [
        "generate_and_save_imamges(model, 0, test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI4wy6uWeSJ1"
      },
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  start_time = time.time()\n",
        "  for train_x in train_dataset:\n",
        "    train_step(model, train_x, optimizer)\n",
        "  end_time - time.time()\n",
        "\n",
        "  loss = tf.keras.metrics.Mean()\n",
        "  for test_z in test_dataset:\n",
        "    loss(compute_loss(model, test_x))\n",
        "  elbo = -loss.result()\n",
        "  display.clear_output(wait=False)\n",
        "  print('Epoch: {}, Test set ELBO: {}, Time: {}'.format(epoch, elbo, (end_time-start_time)))\n",
        "  generate_and_save_imamges(model, epoch, test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWuV_YBU_Fo"
      },
      "source": [
        "## 학습 시각화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "- 마지막 훈련 스텝에서 생성 된 이미지 표"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O0a81TMeT4j"
      },
      "source": [
        "def dispplay_image(epochs_no):\n",
        "  retuen PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "source": [
        "plt.imshow(display_imasho(epoch))\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "- 저장된 모든 이미지의 애니메이션 GIF 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "source": [
        "anim_file = 'cvae.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filenames in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZqAEtdqUmJF"
      },
      "source": [
        "import tensorflow_docs,vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeunRU6TSumT"
      },
      "source": [
        "- 잠재 공간에서 2D 다양한 숫자 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "mNcaaYPBS3mj"
      },
      "source": [
        "def plot_laten_images(model, n ,digit_size=28):\n",
        "  norm = tfp.distributions.Normal(0, 1)\n",
        "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "  image_width = digit_size * n\n",
        "  image_height = image_width\n",
        "  image = np.zeros((image_height, image_width))\n",
        "\n",
        "  for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "      z = np.array([[xi, yi]])\n",
        "      x_decoded = model.sample(z)\n",
        "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
        "      image[i * digit_size: (i+1) * digit_size,\n",
        "            j * digit_size: (j+1) * digit_size] = digit.numpy()\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(image, cmap='Grays_r')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ZG69QCZnGY"
      },
      "source": [
        "plot_latent_images(model, 20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}